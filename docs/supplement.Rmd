---
title: "Supplementary Information for TITLE HERE"
author: "XXXX et al."
date: "6/20/2017"
header-includes:
  - \usepackage{amsmath, amssymb}
bibliography: supp.bib
output: 
  pdf_document:
    fig_caption: true 
---

# Modeling: Case Strength
For the case of a single rating outcome (case strength), we separately model each group of participants as follows: Given a set of
ratings $R$ indexed by $i=1\ldots N$, and an $N \times P$ design matrix $X$ (with columns corresponding to regressors $p=1\ldots P$), we assume for a given observation $i$ corresponding to 
subject $s$ and case $c$:

\begin{align}
  R_i &\sim \left[\mathcal{N}(\theta_i, \sigma^2)\right]^{100}_0 \label{rating}\\
  \theta_i &= X_{i \,\cdot} \cdot \beta_{s(i) c(i) \,\cdot} \label{theta}\\
  \beta_{s c p} &\sim \mathcal{T}_{\nu}(\gamma_{c p}, \tau^2_{c p}) \label{beta}\\
  \gamma_{c p} &\sim \mathcal{T}_{\nu'}(\mu_p, \eta^2_p) \label{gamma}\\
  \mu_p &\sim \mathcal{N}(50, 50) \label{mu} \\
  \eta_p &\sim \mathrm{Ca}^+(0, 50) \\
  \tau_{c p} &\sim \mathrm{Ca}^+(0, 50) \\
  \sigma &\sim \mathrm{Ca}^+(0, 5) \\
  \nu, \nu' &\sim \mathcal{N}^+(0, 100)
\end{align}

That is:

- ratings are generated from a normal distribution censored to lie in the range $[0, 100]$ (\ref{rating})
- linear predictors of ratings are weighted sums of subject-, case-, and regressor-specific effects (\ref{theta})
- $\beta$ effects for each subject are drawn from a case-specific distribution (\ref{beta})
- $\gamma$ effects for each case are themselves drawn from a distribution of effects (\ref{gamma})
- effects at the case and single-subject level are modeled as robuts/fat-tailed, with Student-t distributions (\ref{beta},\ref{gamma})
- variances ($\eta^2$, $\tau^2$, $\sigma^2$) are modeled using weakly informative half-Cauchy priors [@gelman2006prior], 
  while degrees of freedom ($\nu$, $\nu'$) are modeled using weak half-Normal priors

This approach allows for flexible fitting (including estimates of variance) at the regressor, case, and individual levels, while
at the same time leveraging partial pooling to share statistical strength across these levels [@gelman2006data].

# Modeling: Multiple Ratings
For the case in which subjects provide multiple ratings (punishment, case strength, etc.) for a given scenario, we model the resulting
vector of ratings, $R_r$, $r=1\ldots N_r$, similarly

\begin{align}
  R_i &\sim \left[\mathcal{N}(\theta_i, \sigma^2_{r(i)})\right]^{100}_0 \label{rating_m}\\
  \theta_i &= X_{i \,\cdot} \cdot \beta_{s(i) c(i) \,\cdot \,r(i)} \label{theta_m}\\
  \beta_{s c p r} &\sim \mathcal{T}_{\nu}(\gamma_{c p r}, \tau^2_{p r}) \label{beta_m}\\
  \gamma_{c p} &\sim \mathcal{T}_{\nu'}(\mu_p, \Sigma_p) \label{gamma_m}\\
  \Sigma_p &= L_p \cdot \mathrm{diag}(\eta_p)\cdot L_p^\top \\
  \Omega_p = L_p L_p^\top &\sim \mathrm{LKJ}(1) \label{L_m}\\
  \mu_{p r} &\sim \mathcal{N}(50, 50) \label{mu_m} \\
  \eta_{p r} &\sim \mathrm{Ca}^+(0, 50) \\
  \tau_{p r} &\sim \mathrm{Ca}^+(0, 50) \\
  \sigma_r &\sim \mathrm{Ca}^+(0, 5) \\
  \nu, \nu' &\sim \mathcal{N}^+(0, 100)
\end{align}

Here, we have used a "long" or "melted" representation of $R$ in which each index $i$ corresponds to a single observation of a
single rating scale $r(i)$. This allows us to more easily handle missing data in the model fitting procedure (see below). 
The model is almost equivalent to concatenating $N_r$ versions of the first model, one for each rating, 
aside from two key differences: First (\ref{gamma_m}) and (\ref{L_m}) involve a multivariate t-distribution on the population 
effects $\gamma$ specific to 
each case. That is, we allow for covariance among the ratings for each effect at the population level, where the magnitudes of the 
variances are again controlled by $\eta$ and the correlations $\Omega = LL^\top$ are modeled according to the LKJ distribution [@Lewandowski2009-tm]
through their Cholesky factorization (\ref{L_m}).\footnote{Implemented as \texttt{L \textasciitilde{} lkj\_corr\_chol(1)} in Stan.}
Second, in order to more accurately estimate variances in the presence of missing data, we have restricted this model to a single
value of $\tau$ across all cases (for each outcome and regressor) (\ref{beta_m}).

# Model Fitting
We calculated posterior distributions and credible intervals for each variable of interest using Markov Chain Monte Carlo methods
as implemented in the Stan probabilistic programming language [@carpenter2016stan]. Full code for all analyses is available at 
[https://github.com/pearsonlab/legal](https://github.com/pearsonlab/legal). Models were fit by running 4 chains of either 1000 samples (case strength only model) with a thinning fraction of 1 or 2000
samples (multiple outcome models) with a thinning fraction of 2, of which the first half were discarded as burn-in. This resulted 
in 2000 total samples for each variable, for which we report means as well as 95% equal-tailed credible intervals (bounded 
by the 2.5% and 97.5% samples from the distribution). We assessed convergence via effective sample size and the
Gelman-Rubin statistic, for which all runs exhibited $\hat{R} < 1.1$ [@gelman2014bayesian].

# Supplementary Figures

```{r message=FALSE, echo=FALSE, warning=FALSE, fig.height=6, fig.cap="Deserved punishment ratings as a function of crime severity. Plotted separately for State (A) and Federal (B) crimes. \\label{seriousness_by_crime_type}"}
library(tidyverse)
library(grid)
library(gridExtra)
source("../ggplot_setup.R")

load('../data/stan_hier_postprocess_multi.rdata')

# dataframe linking scenarios to seriousness as rank ordered by PS
sc_ranked <- as.factor(c(27, 6, 12, 29, 13, 14, 1, 24, 2, 22, 25,
                                        3, 8, 9, 4, 18, 33, 15, 7, 19, 28, 32, 5, 11, 26, 17,
                                        20, 30, 31, 21, 10, 16, 23))
crime_type <- rep('state', 33)
crime_type[c(1, 14, 28)] <- 'federal'
crime_type <- as.factor(crime_type)

seriousness <- data.frame(seriousness=as.factor(c(1:33)), 
                          scenario=sc_ranked,
                          crime_type=crime_type)

df <- merge(dat, seriousness) %>% filter(rating_type=='rate_punishment') %>% 
  group_by(scenario, seriousness, crime_type) %>% 
  summarise(punish=median(rating), lower=quantile(rating, 0.25), 
            upper=quantile(rating, 0.75))
  

# boxplot punishment rating by seriousness
plt_1 <- ggplot(df %>% filter(crime_type=='state')) +
  geom_pointrange(aes(seriousness, punish, ymin=lower, ymax=upper), color=color_conf) + 
  # geom_smooth(aes(as.numeric(seriousness), punish), color=color_conf, span=0.85, fullrange=TRUE) +
  scale_x_discrete(name='Scenario (rank-ordered by severity)',
                   breaks=c(1:33),
                   labels=seriousness$scenario) + 
  coord_cartesian(ylim=c(0, 100)) +
  labs(title="A. State Crimes", size=rel(3)) +
  ylab("Punishment Rating (points)") +
  th +
  theme(
    axis.text.x = element_text(size=rel(0.75))
    )

plt_2 <- ggplot(df %>% filter(crime_type=='federal')) +
  geom_pointrange(aes(seriousness, punish, ymin=lower, ymax=upper), color=color_conf) + 
  # geom_smooth(aes(as.numeric(seriousness), punish), color=color_conf, span=0.85, fullrange=TRUE) +
  scale_x_discrete(name='Scenario (rank-ordered by severity)',
                   breaks=c(1:33),
                   labels=seriousness$scenario) + 
  coord_cartesian(ylim=c(0, 100)) +
  labs(title="B. Federal Crimes", size=rel(3)) +
  ylab("Punishment Rating (points)") +
  th +
  theme(
    axis.text.x = element_text(size=rel(0.75))
    )
plot(arrangeGrob(plt_1, plt_2))
```


```{r message=FALSE, echo=FALSE, warning=FALSE, fig.width=8, fig.cap="Pairwise correlations for baseline effects across all outcome types. Includes both versions of the threat assessment question (cp. Figure 4C). \\label{baseline_correlations}"}
load('../data/stan_hier_postprocess_multi_all.rdata')

outcomes <- levels(effects$outcome)
Nr <- length(outcomes)
releveler <- function(x) {
  # replace outcome numbers with names
  xfac <- factor(x, levels=1:length(outcomes), labels=outcomes)
  
  # now reorder levels so plot looks right
  factor(as.character(xfac), levels=c("rating", "rate_punishment", "rate_outrage", "rate_threat", "rate_threat_2"))
}
corrs <- effects %>% filter(grepl('rho', variable)) %>% 
                     separate(variable, into=c("variable", "outcome1", "outcome2")) %>%
                     mutate_at(c("outcome1", "outcome2"), releveler) %>%
                     filter(evidence=='baseline') %>% 
                     unite(col=contrast, outcome1, outcome2, sep='-') %>%
                     mutate(contrast=factor(contrast, levels=outcome_corr_levels,
                                                      labels=outcome_corr_labels))

plt_3 <- ggplot(data = corrs) +
  geom_hline(yintercept=0, colour='grey') +
  geom_pointrange(aes(x=contrast, y=X50., ymin=X2.5., ymax=X97.5.)) + 
  ylab('Baseline Correlation') +
  xlab('Outcome Pair') +
  coord_cartesian(ylim=c(-1,1)) +
  th +
  theme(
    axis.text.x = element_text(hjust = 0.5, size=rel(0.8), color='black')
  )
plt_3  
```

```{r message=FALSE, echo=FALSE, warning=FALSE, fig.width=8, fig.cap="Correlations between case strength and deserved punishment for all model effects across groups (cp. Figure 4D). \\label{all_group_correlations}"}

load('../data/stan_hier_postprocess_multi.rdata')

plt_4 <- ggplot(data=(effects %>% filter(variable=='rho'))) +
  geom_hline(yintercept=0, colour='grey') +
  geom_pointrange(aes(x=evidence, y=X50., ymin=X2.5., ymax=X97.5., color=group), 
                         position=position_dodge(width = 0.5)) + 
  xlab('Evidence') + ylab('\nCase Strength /\nPunishment Correlation') +
  group_color_scale +
  evidence_plus_baseline_x_axis +
  th + 
  theme(
    axis.text.x = element_text(hjust = 0.5, size=rel(1), color='black'),
    legend.position=c(0.15, 0.2),
    legend.box.background = element_rect(fill=alpha("white", 0.75), color=NULL, linetype=NULL)
  )
plt_4
```

```{r message=FALSE, echo=FALSE, warning=FALSE, fig.width=8, fig.cap="Comparison of sources of model variance. Points indicate posterior means of variance parameters. Lines indicate 95% credible intervals. Boxplots indicate variability of variance parameters across scenarios. Columns correspond to model variance parameters $\\tau^2$, $\\eta^2$, and $\\sigma^2$, respectively. \\label{model_variance_comparison}"}
############### Panel 5: Variance Comparison #################################
load('../data/stan_hier_postprocess.rdata')
variance_comparison <- effects %>%
  filter(variable %in% c('eta', 'tau', 'sigma'), (evidence=='baseline') | (variable == 'sigma')) %>%
  select(X2.5., X50., X97.5., variable, scenario, group) %>%
  mutate(variable = factor(variable, levels=c('eta', 'tau', 'sigma')))

plt_5 <- ggplot() +
  geom_pointrange(data=variance_comparison %>% filter(variable %in% c('eta', 'sigma')),
                  aes(x=variable, y=X50., ymin=X2.5., ymax=X97.5., color=group),
                  position=position_dodge(width=0.5), size=1) +
  geom_boxplot(data=variance_comparison %>% filter(variable=='tau'),
               aes(x=variable, y=X50., color=group), lwd=1, fatten=1, 
               position=position_dodge(width=0.85)) +
  variance_x_axis +
  group_color_scale +
  ylim(0, 50) +
  ylab("Standard Deviation (points)") + 
  xlab("Variance") +
  labs(title="E", size=rel(3)) +
  th +
  theme(
    axis.text.x = element_text(hjust = 0.5, size=rel(1), color='black'),
    legend.position = c(0.8, 0.8)
  )
plt_5
```


\newpage
# References